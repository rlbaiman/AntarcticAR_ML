{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may have to turn this into a script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X data\n",
    "fp = '/rc_scratch/reba1583/variable_yr_files_4/'\n",
    "\n",
    "IWV = xr.open_mfdataset(fp+'IWV').IWV.values\n",
    "EFLUX = xr.open_mfdataset(fp+'EFLUX').EFLUX.values\n",
    "LWTNET = xr.open_mfdataset(fp+'LWTNET').LWTNET.values\n",
    "SF = xr.open_mfdataset(fp+'SF').sf.values\n",
    "SLP = xr.open_mfdataset(fp+'SLP').SLP.values\n",
    "T = xr.open_mfdataset(fp+'T').T.values\n",
    "U = xr.open_mfdataset(fp+'U').U.values\n",
    "V = xr.open_mfdataset(fp+'V').V.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.stack([ IWV, EFLUX, LWTNET,\n",
    "                 SF, SLP, T, U, V])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del V \n",
    "del U\n",
    "del T\n",
    "del IWV\n",
    "del EFLUX\n",
    "del SF\n",
    "del SLP\n",
    "del LWTNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y data\n",
    "Y = xr.open_mfdataset('/rc_scratch/reba1583/Y_data/Y_AR_only.nc')\n",
    "Y = Y.Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# times for final xarray\n",
    "variable_times = xr.open_mfdataset(fp+'U').time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_data = dict(\n",
    "    features = (['n_channel', 'time', 'lat', 'lon' ], data),\n",
    "    labels_2d = (['time', 'lat', 'lon'], Y)\n",
    ")\n",
    "\n",
    "coords = dict(\n",
    "    n_channel = (['n_channel'], np.array(['IWV', 'EFLUX', 'LWTNET', 'SF', 'SLP', 'T', 'U', 'V'])),\n",
    "    time = (['time'], pd.to_datetime(np.array(variable_times))),\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset(\n",
    "    data_vars = var_data, \n",
    "    coords = coords\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape here - compare to 4day testing I think you need to rearrange them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get even number of timesteps with/without ARs\n",
    "AR_index = np.squeeze(np.where(ds.Y.max(dim = ('lat','lon')).load()==1))\n",
    "noAR_index = np.setdiff1d(np.arange(len(ds.time)), AR_index)\n",
    "np.random.shuffle(noAR_index)\n",
    "noAR_index = noAR_index[0:len(AR_index)]\n",
    "select = np.sort(np.concatenate((noAR_index, AR_index)))\n",
    "data = ds.isel(time = select)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training, validating, and testing\n",
    "index = np.arange(len(y_data.time))\n",
    "split1, split2 = int(.7*len(index)), int(.85*len(index))\n",
    "\n",
    "np.random.shuffle(index)\n",
    "index_train, index_validate, index_test = index[:split1], index[split1:split2], index[split2:]\n",
    "index_train.sort()\n",
    "index_validate.sort()\n",
    "index_test.sort()\n",
    "\n",
    "ds_train = data.isel(time = index_train)\n",
    "ds_test = data.isel(time = index_test)\n",
    "ds_validate = data.isel(time = index_validate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.to_netcdf('rc_scratch/reba1583/train')\n",
    "ds_test.to_netcdf('rc_scratch/reba1583/test')\n",
    "ds_validate.to_netcdf('rc_scratch/reba1583/validate')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
